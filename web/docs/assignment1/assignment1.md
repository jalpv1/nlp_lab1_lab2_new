# Task N1. Entropy of a Text
## Task N1.1 Compute this conditional entropy and perplexity for the file TEXTEN1.txt
Number of unique words in texten1 8696
Number of unique words in textcz1 38355
Conditional entropy 16.632213563461573
Perplexity PX = 101576.95199856724
## Task N1.2 Mess up with text and measure how it affects entropy for the file TEXTEN1.txt
### Entropies of texten1 with messed CHARs
|      Probability, %      |       Min Entropy        |       Max Entropy        |       Avg Entropy        |
| ------------------------ | ------------------------ | ------------------------ | ------------------------ |
| 10                       | 16.645908036600474      | 17.072088910063208      | 16.7514786672772         |
| 5                        | 16.65822261512475       | 17.20607115997253       | 16.760157588499307       |
| 1                        | 16.64336271476594       | 16.97534625617999       | 16.76977414861971        |
| 0.1                      | 16.6375204631289        | 16.966428659038403      | 16.73653466799405        |
| 0.01                     | 16.667142666174364      | 16.899209396774086      | 16.776745996696064       |
| 0.001                    | 16.6475634179364        | 17.128082824571024      | 16.771935367008776       |

### Entropies of texten1 with messed WORDs
|      Probability, %      |       Min Entropy        |       Max Entropy        |       Avg Entropy        |
| ------------------------ | ------------------------ | ------------------------ | ------------------------ |
| 10                       | 17.618813105896308      | 17.735474659431055      | 17.681821681425294       |
| 5                        | 17.659148386133378      | 17.80453664851131       | 17.692784388377394       |
| 1                        | 17.667321618924834      | 17.778266182340648      | 17.718508117457084       |
| 0.1                      | 17.64003989889734       | 17.782517548793653      | 17.7052772570593         |
| 0.01                     | 17.619679931287322      | 17.724862607194375      | 17.67710996753906        |
| 0.001                    | 17.663570105000083      | 18.16493080441218       | 17.746374495254145       |

### Entropies of textcz1 with messed CHARs ---
|      Probability, %      |       Min Entropy        |       Max Entropy        |       Avg Entropy        |
| ------------------------ | ------------------------ | ------------------------ | ------------------------ |
| 10                       | 7.677233944263574       | 7.773896568146764       | 7.710968043846387        |
| 5                        | 7.632015598808963       | 7.862473776047637       | 7.708224105648284        |
| 1                        | 7.66523733721306        | 7.772500393312858       | 7.711744633838743        |
| 0.1                      | 7.682184697278724       | 7.867015647060596       | 7.754207667773201        |
| 0.01                     | 7.6633069770173075      | 7.785362372420678       | 7.711850835400831        |
| 0.001                    | 7.675252576464138       | 7.802181761550659       | 7.730426304507577        |

### Entropies of textcz1 with messed WORDs
|      Probability, %      |       Min Entropy        |       Max Entropy        |       Avg Entropy        |
| ------------------------ | ------------------------ | ------------------------ | ------------------------ |
| 10                       | 8.158542204291548       | 8.181760348112572       | 8.167542932635612        |
| 5                        | 8.154929518803398       | 8.179935458677653       | 8.169078858576752        |
| 1                        | 8.157515995001857       | 8.182612259865753       | 8.168562628494156        |
| 0.1                      | 8.156104802775511       | 8.181329891017128       | 8.16609720815163         |
| 0.01                     | 8.15691499298978        | 8.177291178073979       | 8.165885020023808        |
| 0.001                    | 8.15873589129673        | 8.177258510240236       | 8.168730456544557        |

### Entropy when CHARs are messed in TEXTEN1
![alt text for screen readers](texten1_chars.jpg)
### Entropy when WORDs are messed in TEXTEN1
![alt text for screen readers](texten1_words.jpg)
### Entropy when CHARs are messed in TEXTCZ1
![alt text for screen readers](textcz1_chars.jpg)
### Entropy when WORDs are messed in TEXTCZ1
![alt text for screen readers](textcz1_words.jpg)
